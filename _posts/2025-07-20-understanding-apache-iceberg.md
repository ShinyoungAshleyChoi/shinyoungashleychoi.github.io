---
layout: post
title: Understanding Apache Iceberg (1) - Introduction
tags: ["iceberg", "bigdata", "datalake"]
---

_이 글의 내용은 Apache Iceberg: The Definite Guide (O'Reily)의 내용을 정리한 것 입니다._

# Apache Iceberg 소개
 - 성능 및 일관성 외 여러 Hive의 약점들을 극복하기 위해 Netflix에서 개발한 **테이블 포맷**

## 테이블 포맷이란? - _"What data is in this table?"_
> A table format is a method of structuring a dataset's files to present them as a unified "table". From the user's perspective, it can be defined as the answer to the question "what data is in this table?"[^1]

- 단 위의 내용을 직역하여 단순히 "이 테이블에는 어떤 데이터가 들어있는가?"로 이해한다면 오해의 여지가 있음. - 기존의 전통적인 방식의 RDB에서처럼 employees 테이블에 (홍길동, 영업팀) 따위의 레코드가 들어있다는 것으로 오해하기 쉬음.
- 과거에는 각 데이터베이스의 저장 엔진이 데이터의 읽기/쓰기를 단독적으로 관리했지만 빅데이터 시대가 열린 이후로 이 방법은 더이상 실용적이지 않게 됨
- 데이터 레이크 시대에는 데이터가 대용량 저장 솔루션(e.g. AWS s3, Azure Data Lake Storage, Google Cloud Storage)에 파일 형태로 존재하며 단일 테이블은 이러한 수백, 수천, 수백만의 개별 파일들로 이루어져있음.
- 이러한 데이터 레이크 관점에서 "이 테이블이 참조하고 있는 파일들에는 각각 어떤 데이터가 포함되어 있는가?"로 이해하는 것이 맞다고 보임.
- 어떤 sql이나 애드혹 스크립트를 실행하기 위해 어떤 파일에 어떤 데이터가 들어 있는지를 일일이 파악하고 싶지는 않을 것.
- 다른 말로 표현하면, 데이터셋의 파일들을 통일된 테이블로 표현하기 위해 구조화하는 방법

## Iceberg 이전의 세계에는 Hive가 존재
### Hive의 특징
- 하둡 데이터 레이크 하에서는 데이터 분석에 맵리듀스 프레임워크를 사용, 사용자들은 복잡하고 지루한 자바 작업을 해야했음
- 맵리듀스 잡 대신 SQL을 사용하여 편리하게 데이터 분석을 할 수 있도록 등장한 것이 Hive.
- Hive는 SQL을 실행 가능한 맵리듀스 잡으로 변환
- 하지만 SQL문을 작성할때도, Hadoop 스토리지에 저장된 데이터 중 어떤 게 고유한 테이블을 나타내는지 알 수 있는 메커니즘이 필요, 이것이 Hive 테이블 포맷과 테이블 정보를 관리, 추적하는 Hive Metastore가 탄생한 이유.
- Hive 테이블 포맷은 지정된 디렉터리에 들어 있는 모든 파일을 하나로 봄
  - 그 디렉터리 안의 하위 디렉터리가 곧 파티션이 됨
  - 이 디렉터리 경로 전체를 Hive Metastore 가 기록하고 관리.

### Hive의 장점
- 파티션이나 버켓팅같은 기술 덕분에 풀 스캔없이 필요한 데이터만 빠르게 조회 가능
- 파일 포맷에 독립적 - Parquet, Avro, CSV/TSV같은 다양한 포맷의 파일을 읽기 가능
- Hive Metastore에 리스팅된 디렉터리의 원자적 스왑을 통해 테이블의 개별 파티션 단위로 원자적 변경이 가능. 

### Hive의 단점
- 파일 레벨의 변경은 비호율적. 파티션 디렉터리를 변경하는 것처럼 원자적으로 파일을 바꿀 수 있는 메커니즘은 없었음
- 파티션을 원자적으로 스왑할 때, 한 트랜잭션에 여러 파티션을 원자적으로 업데이트 할 수 있는 메커니즘은 없었기 때문에 여러 파티션을 업데이트 하는 동안에는 일관성이 깨질 수 있음
- 동시 업데이트를 가능하게 하는 메커니즘이 존재하지 않음 (사실 Hive를 뛰어넘는 툴들에서도!)
- 파일과 디렉터리 리스트를 나열하는데 시간이 소요되고 쿼리를 느리게 만듦, 스캐닝이 필요 없는 파일이나 디렉터리까지 리스팅하기 때문에 쿼리 결과를 얻는데 추가적인 비용 소모.
- 파티션 컬럼은 종종 다른 컬럼에서 파생되어 만들어짐. - 타임스탬프로부터 월 컬럼을 만드는 경우, 파티션 컬럼으로 필터링할 경우에는 파티셔닝이 도움이 되지만 타임스탬프 컬럼으로 필터링하는 쿼리는 파생된 월컬럼을 함께 필터링 해야 한다는 사실을 직관적으로 알기 어려워 전체 테이블을 스캔하는 문제 발생.
- 테이블 통계는 비동기적으로 수집되어 통계 정보가 없거나 오래된 경우 발생, 쿼리 엔진이 추가적인 최적화를 수행하는데 어려움을 겪음
- 데이터 셋과 사용 사례의 규모가 커질 수록 위 문제들은 더욱 심각해짐

## 현대 데이터 레이크 테이블 포맷
- 현대 데이터 레이크 테이블 포맷의 창시자들은 Hive 테이블 포맷이 겪는 문제의 원인은 개별 파일이 아닌 디렉터리 내용 기반의 테이블 정의라는 것을 깨달음
- Apache Iceberg, Apache Hudi, Delta Lake와 같은 현대 테이블 포맷들은 모두 이러한 접근 법을 따름, 메타데이터는 "어떤 파일들이(디렉터리가 아니라!) 테이블을 구성하느냐"를 엔진에게 알려줌
- 이러한 접근 법은 ACID 트랜잭션, 동시 쓰기 중 일관성 유지, 더 나은 통계 정보와 메타데이터 제공, 타임 트레블 등과 같은 새로운 세계로의 문을 열어줌

### Iceberg의 목표
- 일관성(Consistency): 여러 파티션에 걸쳐 데이터가 업데이트 되는 경우, 이는 빠르고 원자적으로 이루어져야 하며 사용자는 업데이트 전 혹은 후 상태만을 볼 수 있어야 한다. 즉, 어떤 파티션에는 업데이트가 적용되어 있고, 어떤 파티션에는 적용이 되지않은 중간(일관성이 깨진) 상태를 목격해서는 안된다.
- 성능(Performance): 테이블은 메타데이터를 제공하고 과도한 파일 나열을 피해야함, 그렇게 함으로써 쿼리 계획 과정 자체가 더 빨라지고 쿼리 계획이 필요한 파일만 스캔하므로 훨씬 빠르게 실행될 수 있음
- 사용 용이(Easy to Use): 파티셔닝 같은 기술의 이점을 얻으려면, 최종 사용자는 테이블의 물리적 구조를 알 필요가 없어야함, 테이블은 사용자에게 자연스럽고 직관적인 쿼리를 통해 파티셔닝의 이점을 제공할 수 있어야하고 이미 필터링하고 있는 컬럼(e.g. 타임스탬프 컬럼)에서 파생된 추가적인 파티션 컬럼(e.g. month 컬럼)을 또 필터링하는 방식에 의존하지 않아야 함.
- 진화/변경 가능함 (Evolvability): Hive 테이블의 스키마를 수정하면 안전하지 않은 트랜잭션 발생 가능, 테이블의 파티셔닝 방식을 변경할 때에는 전체 테이블 다시 작성 필요, 테이블은 스키마와 파티셔닝의 방식을 안전하게 변경할 수 있어야 하며 이를 위해 전체 재작성할 필요가 없어야 함.
- 확장성 (Scalability): 위 요구사항들이 페타바이트급 데이터에서 달성 가능해야 함. (Iceberg는 넷플릭스에서 만들었음!)


[^1]: *Apache Iceberg: The Definitive Guide*, O'Reilly Media, 2023. p.16
