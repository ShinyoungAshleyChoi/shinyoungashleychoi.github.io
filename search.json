[

{
"title": "[사이드프로젝트] MCP로 AI에 내 헬스 데이터 연결하기! (기획 &amp; 간단 설계)",
"url": "/MCP-health-data-project-planning/",
"content": "MCP로 AI에 내 헬스 데이터 연결하기!1. 프로젝트 개요  프로젝트명: Real-time Health Data MCP Server (AI Agent Query Focus)  배경 및 필요성          스마트폰과 웨어러블을 통한 개인 헬스 데이터 수집이 일상화되면서, AI가 실시간으로 데이터에 접근하여 분석·피드백을 주는 서비스 수요 증가.      기존 헬스 데이터 분석은 배치 처리 중심이라, 즉각적인 사용자 질의응답에 제약이 있음.        목표          iOS HealthKit과 MCP 서버를 연동해 실시간 헬스 데이터를 안전하게 수집하고, AI Agent가 대화 중에 바로 질의·응답할 수 있는 환경을 구축.      2. 주요 기능  실시간 헬스 데이터 수집 (걸음수, 심박수, 수면, 운동)  이벤트 기반 증분 동기화 (Observer Query + Anchored Query)  안전한 데이터 전송 (HTTPS/mTLS, Token 인증)  원본 데이터 Parquet 저장 (일 단위 파티션)  DuckDB 기반 빠른 질의 처리 (최근 데이터 위주)  MCP Tools: getSteps, getWorkouts, getHeartRateStats  MCP Resources: weekly_report.md(주간 리포트), 일간 요약 Parquet3. 시스템 아키텍처      데이터 흐름:    iOS 브리지 앱 → HTTPS/mTLS 전송 → MCP 서버 → Parquet 저장 → DuckDB 질의 → MCP Tools/Resources → AI Agent    저장 구조:          bronze/quantity_events/dt=YYYY-MM-DD/*.parquet      bronze/workouts/dt=YYYY-MM-DD/*.parquet        쿼리 처리 방식:          최근 30일 캐시(Parquet) → DuckDB → 응답      범위 초과 시 직접 Parquet 스캔      4. 기술 스택  클라이언트(iOS): Swift/SwiftUI, HealthKit API  서버: Python + FastAPI, Node.js, @modelcontextprotocol/sdk  저장소: Parquet (S3 또는 로컬), DuckDB  보안: TLS/mTLS, Bearer Token 인증  기타: Docker, GitHub Actions(CI/CD)5. 데이터 모델  Quantity 데이터: 걸음수, 심박수 등 (value, unit, start_ts, end_ts, uuid)  Category 데이터: 수면 분석, 활동 상태 등 (value, start_ts, end_ts, uuid)  Workout 데이터: 운동 타입, 거리, 시간, 칼로리 등 (activity, distance, duration, energy)  메타데이터: uuid, ingest_ts, device_id, dt 파티션6. 보안 및 개인정보 보호 정책  HealthKit 권한 최소화 (필요 데이터 타입만 요청)  모든 전송 구간 TLS/mTLS 암호화  Token 기반 인증 및 Rate Limit 적용  민감 데이터 로깅 금지  삭제 이벤트 수신 시 Parquet에서 삭제 반영7. 활용 시나리오  AI 대화형 질의: “지난 7일 걸음수 평균 보여줘” → MCP Tool 호출 → DuckDB 응답  운동 분석: “최근 러닝 워크아웃 요약해줘” → Parquet 필터링 후 결과 반환  건강 리포트 자동 생성: 주간 데이터 집계 후 weekly_report.md 생성8. 프로젝트 일정—9. 확장 방안1. 데이터 레이어 확장 (Bronze → Silver → Gold)  Bronze Layer (원본 저장)          HealthKit에서 수집한 원본 데이터를 Parquet로 일 단위 파티션 저장      중복/결측 포함, 원본 그대로 유지 → 재처리, 오류 복구 가능        Silver Layer (정제·표준화)          Iceberg 테이블로 관리, 스키마 표준화, 단위 변환, 다중 기기 데이터 병합      ACID 트랜잭션 및 스냅샷 기능으로 데이터 정합성 확보        Gold Layer (집계·최종 분석)          Airflow ETL로 주간/월간 통계 생성 (예: daily_steps, weekly_hr_stats)      AI Agent 및 대시보드가 즉시 사용할 수 있는 형태로 제공      2. 기술 확장  배치 파이프라인 도입          Apache Airflow + PySpark 기반 ETL로 실버/골드 테이블 갱신      스케줄러를 통한 자동화 및 모니터링        장기 분석 지원          Iceberg를 통한 수년치 데이터 관리 및 schema evolution 지원      장기 추세 분석, 사용자 맞춤형 건강 코칭 모델 가능        실시간 + 배치 하이브리드          현재 실시간 MCP Tools 기반 질의에, 배치 기반 MCP Resources를 결합      최신 데이터 + 누적 통계 모두 대응 가능        이상 감지 시 알림 기능 추가          규칙: 절대 임계, 급상승, 급격 변화, 휴지기(쿨다운)      채널: APNs + 카톡 + Email(백업)      운영: 개인 임계값 학습, 오탐 감소 로직, 일시중지 토글      ",
"tags": ["mcp", "vibe-coding", "real-time"]
},

{
"title": "Understanding Apache Iceberg (3) - Architecture",
"url": "/architecture-of-apache-iceberg/",
"content": "이 글의 내용은 Apache Iceberg: The Definite Guide (O’Reilly)의 내용을 정리한 것 입니다.Apache Iceberg의 아키텍쳐데이터 레이어(The Data Layer)  테이블의 실제 데이터를 저장하며 삭제 파일을 포함  데이터 레이어 의 파일은 Apache Iceberg 테이블의 트리 구조의 리프 노드들로 구성되어 있음  분산 파일 시스템 기반 (HDFS, Amazon S3, ADLS, GCS, …)데이터 파일(Datafiles)  말 그대로 실제 데이터를 저장하는 파일  여러 가지 파일 포맷을 지원, 내장 기능으로는 Apache Parquet, Apache ORC, Apache Avro를 지원          필요에 따라 적합한 파일 포맷을 이용하면 됨 (eg. 대규모 OLAP 분석 - parquet, 스트리밍 분석 테이블 - avro)      필요에 의해 파일 포맷이 변경되어 여러 파일 포맷이 혼재되어도 그대로 사용 가능      새로운 개선된 파일 포맷이 개발된다면 이를 적용할 수도 있음        여러 파일 포맷을 지원하지만 사실상 표준이 되는 것은 parquet 형식임          이는 컬럼 기반 구조가 행 기반 구조보다 대규모 OLAP에 적합하기 떄문      그 밖에, 하나의 파일을 여러 방식으로 분할해서 병렬성을 높일 수 있음      각 분할 지점에 대한 통계 정보를 가질 수 있어서 필터 푸쉬다운이나 스킵리드가 가능      압축 효율이 좋아서 저장 공간을 적게 차지하고 읽기 속도가 높아지는 이점이 있음      Parquet 파일의 내부 구조                              parquet 파일 아키텍쳐1        Row Group 0 은 하나의 로우 집합이며 각 컬럼에 대응되는 행들의 값이 모여 있는 집합으로 구성되며 이는 다시 페이지라는 단위로 분할 된다. 이렇게 나뉜 각 계층은 엔진이나 툴이 독립적으로 읽어올 수 있다  각 row group 에 대한 통계 정보(e.g., 어느 컬럼의 최소값, 최대값 등)을 가지고 있다. 이 통계 정보를 기반으로 쿼리 실행 시 해당 row group을 읽을지 말지 결정할 수 있다.삭제 파일(Delete Files)  삭제 파일은 데이터셋에서 어느 레코드가 삭제되었는지를 추적한다.  레코드가 삭제되면 변경분이 반영된 새 파일이 작성되거나 (copy-on-write [COW])  변경 분만을 기록한 새 파일이 작성되고 데이터를 읽을 때 이를 병합해서 보여줄 수 있다(merge-on-read [MOR])  수정/삭제 성능을 위해 MOR 방식을 취한다.  위치 삭제 파일(Positional delete files): 삭제된 행의 위치를 식별 하여 어떤 행이 논리적으로 삭제되었는지를 나타냄  균등 삭제 파일(Equality delete files): 컬럼 값 기반 삭제, 특정 조건 (특히 pk)에 해당하는 행을 논리적으로 삭제 처리하여 나타냄          그렇다면.. 어떤 조건에 해당하는 행을 삭제 한 후 새롭게 추가된 행이 그 조건에 해당한다면 어떻게 될까? 이 새로운 레코드 역시 삭제 처리되는 건 아닐까?      이를 해결 하기 위해 시퀀스 넘버를 활용한다. 모든 파일(data file, delete file)에는 고유한 시퀀스 번호가 할당되고 균등 삭제 파일은 자신보다 같거나 작은 수의 data file에만 적용함      메타데이터 레이어(The Metadata Layer)매니페스트 파일(Manifest Files)  매니페스트 파일은 데이터 레이어의 파일들(datafiles/delete files)과 각 파일의 추가적인 세부사항과 통계 정보들을 추적한다.  Hive와 구별되는 Iceberg의 특징이 바로 파일 레벨에서 어떤 데이터가 속해있는지를 추적한다는 것이다. (디렉터리 레벨이 아니라!)  매니페스트 파일은 메타데이터 트리의 말단 노드 레벨에서 이를 수행하는 파일이다.  매니페스트 파일의 내용은 해당 데이터 파일의 경로, 포맷, 어느 파티션에 속해 있는지, 레코드 개수, 컬럼의 최솟값 및 최댓값등을 포함  즉, 통계 데이터를 위해 데이터 파일을 열 필요가 줄어듦. -&gt; 성능 향상  실제 매니페스트 파일의 실제 내용을 보면 이해가 더 쉬웠음!  메니페스트 파일 예시 (실제로는 avro 포맷이지만 편의상 json으로 변환한 것)메니페스트 리스트(Manifest Lists)  매니페스트 리스트는 어떤 주어진 시점의 Iceberg 테이블의 스냅샷을 의미  해당 시점의 매니페스트 파일들과 해당 매니페스트 파일이 참조하는 데이터 파일의 위치, 속한 파티션, 파티션 컬럼의 최댓값, 최솟값을 포함  매니페스트 리스트는 어레이로 감싼 스트럭트 타입을 포함하며 각 스트럭트는 단일 매니페스트 파일을 추적한다.  매니페스트 리스트 예시 (실제로는 avro 포맷이지만 편의상 json으로 변환한 것)메타데이터 파일(Metadata Files)  메타데이터 파일은 메니페스트 리스트를 추적한다.  메타데이터 파일은 특정 시점의 Iceberg 테이블에 관한 메타데이터를 저장한다.  각 시점 마다 변경이 이루어지면 메타데이터 파일이 생성되고 카탈로그에 의해 원자적으로 최신 메타데이터 파일로 등록된다.  테이블 커밋 히스토리는 선형적이며 다중 쓰기에 도움을 준다.  메타데이터 파일 예시퍼핀 파일(Puffin Files)  퍼핀 파일은 좀 더 넓은 범위의 쿼리의 성능을 향상시키기 위해 데이터에 관련된 통계정보와 인덱스들을 저장한다.  퍼핀 파일은 블롭(blob)이라는 임의의 시퀀스 셋과 블롭을 분석하는데 필요한 메타데이터가 포함되어 있다.  현재는 Apache DataSketches 라이브러리의 Theta sketch(bloom filter와 같은 확률적 알고리즘-근사 알고리즘의 일종) 타입만을 지원  Theta sketch는 주어진 행 집합에서 특정 컬럼의 고유 값 개수를 근사 계산할 수 있는 알고리즘이다. 연산 속도가 빠르고 리소스를 적게 쓸 수 있다.  정확한 값을 구하는데 비용이나 시간이 너무 많이 드는 경우, 동일한 연산을 반복해서 실행하는 경우 (대시보드)에 유용카탈로그(Catalog)  Iceberg 테이블의 현재 메타데이터 파일 위치를 추적하고 읽기/쓰기 엔진이 테이블의 최신 상태를 알게 해준다.  메타데이터 파일 경로를 찾으면 테이블 상태 (스키마, 스냅샷 등)을 확인 가능  SQL쿼리로 최신 메타데이터 경로 조회 가능      SELECT *FROM my_catalog.iceberg_book.orders.metadata_log_entriesORDER BY timestamp DESCLIMIT 1                  https://parquet.apache.org/docs/file-format/ &#8617;      ",
"tags": ["iceberg", "bigdata", "datalake"]
},

{
"title": "Understanding Apache Iceberg (2) - Key Features",
"url": "/key-features-of-apache-iceberg/",
"content": "이 글의 내용은 Apache Iceberg: The Definite Guide (O’Reilly)의 내용을 정리한 것 입니다.Apache Iceberg의 주요 특징ACID 트랜잭션  ACID 보장을 위해 낙관적 동시성(optimistic concurrency) 적용  낙관적 동시성(optimistic concurrency)은 락(lock)의 최소화와 성능 향상을 위해 트랜잭션들이 서로 충돌하지 않음을 가정하며 필요할 때만 충돌을 확인한다. 커밋에 성공하거나 실패하거나 둘 중 한가지 상태만 존재한다.  비관적 동시성(pessimistic concurrency)모델에서는 충돌이 일어날 것을 가정하여 트랜잭션 간 충돌을 방지하기 위한 락을 사용한다. 이는 현 시점에서는 Apache Iceberg에 적용 불가능하나 추후에는 가능할 수도 있다.  동시성 보장은 카탈로그(catalog - (3) Architecture 편에서 자세히)가 다룬다.파티션 진화 (Partition evolution)  Apache Iceberg 이전의 데이터 레이크 환경에서의 큰 골칫거리 중 하나는 태이블의 물리적 최적화 변경  파티셔닝을 변경해야 할 때 선택 가능한 유일한 방법은 전체 테이블을 다시 쓰는 것, 아니면 현재 파티셔닝을 유지하면서 잠재적 성능 향상을 희생하는 것이었음  Apache Iceberg에서는 파티셔닝 변경을 위해 메타데이터만 수정되면 되므로 테이블과 전체 데이터를 다시 쓰지 않고 언제든 파티셔닝을 업데이트 할 수 있음      아래 그림에서, 파티셔닝은 처음에는 month를 기준으로 되었다가 day기준으로 변경됨, 이전 파티셔닝과 변경된 파티셔닝이 적용된 데이터를 모두 가져올 때 파티셔닝 방식에 따라 실행계획이 분리됨                                                                  그림11                    숨겨진 파티셔닝 (Hidden Partitioning)  Hive나 전통적인 시스템에서는 timestamp 컬럼으로 파티셔닝 하면, 내부적으로는 event_year, event_month, event_day같은 식으로 다른 컬럼들이 생성되어 파티셔닝됨  event_timestamp &gt;= DATE_SUB(CURRENT_DATE, INTERVAL 90 DAY)  Hive에서 최근 90일간의 평균 수익을 얻기 위해 위와 같은 필터링을 한다면, event_year, event_month, event_day를 직접 필터링하는게 아니기 때문에 전체 스캔을 하게 됨  하지만 Apache Iceberg에서는 파티셔닝 컬럼을 직접 쿼리할 필요가 없도록 내부에서 자동으로 처리해줌행 기반 테이블 운영 (Row-level table operations)  Apache Iceberg에서는 행 단위 업데이트를 copy-on-write(COW) 혹은 merge-on-read(MOR) 방식으로 처리  Copy-on-write(COW): 한 행이라도 변경 발생시 전체 파일을 새로 씀  Merge-on-read(MOR)          변경된 행들만 새로운 파일에 저장해두고 읽을 때 최신상태로 합쳐서 보여줌      무거운 수정&amp;삭제 작업을 가볍게 처리 가능      타임 트래블  Apache Iceberg는 불변 스냅샷을 제공하여 테이블의 히스토리컬 상태에 접근 가능하며 과거 시점을 기준으로 쿼리를 실행할 수 있음버전 롤백  물론 과거 시점의 데이터에 접근하는 것 뿐만 아니라 해당 시점의 스냅샷으로 테이블을 되돌릴 수도 있음스키마 진화 (Schema evolution)  컬럼 추가/삭제, 컬럼 이름 변경, 컬럼 데이터 타입 변경등이 가능            https://www.dremio.com/blog/future-proof-partitioning-and-fewer-table-rewrites-with-apache-iceberg/ &#8617;      ",
"tags": ["iceberg", "bigdata", "datalake"]
},

{
"title": "Understanding Apache Iceberg (1) - Introduction",
"url": "/introduction-of-apache-iceberg/",
"content": "이 글의 내용은 Apache Iceberg: The Definite Guide (O’Reilly)의 내용을 정리한 것 입니다.Apache Iceberg 소개  성능 및 일관성 외 여러 Hive의 약점들을 극복하기 위해 Netflix에서 개발한 테이블 포맷테이블 포맷이란? - “What data is in this table?”  A table format is a method of structuring a dataset’s files to present them as a unified “table”. From the user’s perspective, it can be defined as the answer to the question “what data is in this table?”1  단 위의 내용을 직역하여 단순히 “이 테이블에는 어떤 데이터가 들어있는가?”로 이해한다면 오해의 여지가 있음. - 기존의 전통적인 방식의 RDB에서처럼 employees 테이블에 (홍길동, 영업팀) 따위의 레코드가 들어있다는 것으로 오해하기 쉬음.  과거에는 각 데이터베이스의 저장 엔진이 데이터의 읽기/쓰기를 단독적으로 관리했지만 빅데이터 시대가 열린 이후로 이 방법은 더이상 실용적이지 않게 됨  데이터 레이크 시대에는 데이터가 대용량 저장 솔루션(e.g. AWS s3, Azure Data Lake Storage, Google Cloud Storage)에 파일 형태로 존재하며 단일 테이블은 이러한 수백, 수천, 수백만의 개별 파일들로 이루어져있음.  이러한 데이터 레이크 관점에서 “이 테이블이 참조하고 있는 파일들에는 각각 어떤 데이터가 포함되어 있는가?”로 이해하는 것이 맞다고 보임.  어떤 sql이나 애드혹 스크립트를 실행하기 위해 어떤 파일에 어떤 데이터가 들어 있는지를 일일이 파악하고 싶지는 않을 것.  다른 말로 표현하면, 데이터셋의 파일들을 통일된 테이블로 표현하기 위해 구조화하는 방법Iceberg 이전의 세계에는 Hive가 존재Hive의 특징  하둡 데이터 레이크 하에서는 데이터 분석에 맵리듀스 프레임워크를 사용, 사용자들은 복잡하고 지루한 자바 작업을 해야했음  맵리듀스 잡 대신 SQL을 사용하여 편리하게 데이터 분석을 할 수 있도록 등장한 것이 Hive.  Hive는 SQL을 실행 가능한 맵리듀스 잡으로 변환  하지만 SQL문을 작성할때도, Hadoop 스토리지에 저장된 데이터 중 어떤 게 고유한 테이블을 나타내는지 알 수 있는 메커니즘이 필요, 이것이 Hive 테이블 포맷과 테이블 정보를 관리, 추적하는 Hive Metastore가 탄생한 이유.  Hive 테이블 포맷은 지정된 디렉터리에 들어 있는 모든 파일을 하나로 봄          그 디렉터리 안의 하위 디렉터리가 곧 파티션이 됨      이 디렉터리 경로 전체를 Hive Metastore 가 기록하고 관리.      Hive의 장점  파티션이나 버켓팅같은 기술 덕분에 풀 스캔없이 필요한 데이터만 빠르게 조회 가능  파일 포맷에 독립적 - Parquet, Avro, CSV/TSV같은 다양한 포맷의 파일을 읽기 가능  Hive Metastore에 리스팅된 디렉터리의 원자적 스왑을 통해 테이블의 개별 파티션 단위로 원자적 변경이 가능.Hive의 단점  파일 레벨의 변경은 비호율적. 파티션 디렉터리를 변경하는 것처럼 원자적으로 파일을 바꿀 수 있는 메커니즘은 없었음  파티션을 원자적으로 스왑할 때, 한 트랜잭션에 여러 파티션을 원자적으로 업데이트 할 수 있는 메커니즘은 없었기 때문에 여러 파티션을 업데이트 하는 동안에는 일관성이 깨질 수 있음  동시 업데이트를 가능하게 하는 메커니즘이 존재하지 않음 (사실 Hive를 뛰어넘는 툴들에서도!)  파일과 디렉터리 리스트를 나열하는데 시간이 소요되고 쿼리를 느리게 만듦, 스캐닝이 필요 없는 파일이나 디렉터리까지 리스팅하기 때문에 쿼리 결과를 얻는데 추가적인 비용 소모.  파티션 컬럼은 종종 다른 컬럼에서 파생되어 만들어짐. - 타임스탬프로부터 월 컬럼을 만드는 경우, 파티션 컬럼으로 필터링할 경우에는 파티셔닝이 도움이 되지만 타임스탬프 컬럼으로 필터링하는 쿼리는 파생된 월컬럼을 함께 필터링 해야 한다는 사실을 직관적으로 알기 어려워 전체 테이블을 스캔하는 문제 발생.  테이블 통계는 비동기적으로 수집되어 통계 정보가 없거나 오래된 경우 발생, 쿼리 엔진이 추가적인 최적화를 수행하는데 어려움을 겪음  데이터 셋과 사용 사례의 규모가 커질 수록 위 문제들은 더욱 심각해짐현대 데이터 레이크 테이블 포맷  현대 데이터 레이크 테이블 포맷의 창시자들은 Hive 테이블 포맷이 겪는 문제의 원인은 개별 파일이 아닌 디렉터리 내용 기반의 테이블 정의라는 것을 깨달음  Apache Iceberg, Apache Hudi, Delta Lake와 같은 현대 테이블 포맷들은 모두 이러한 접근 법을 따름, 메타데이터는 “어떤 파일들이(디렉터리가 아니라!) 테이블을 구성하느냐”를 엔진에게 알려줌  이러한 접근 법은 ACID 트랜잭션, 동시 쓰기 중 일관성 유지, 더 나은 통계 정보와 메타데이터 제공, 타임 트레블 등과 같은 새로운 세계로의 문을 열어줌Iceberg의 목표  일관성(Consistency): 여러 파티션에 걸쳐 데이터가 업데이트 되는 경우, 이는 빠르고 원자적으로 이루어져야 하며 사용자는 업데이트 전 혹은 후 상태만을 볼 수 있어야 한다. 즉, 어떤 파티션에는 업데이트가 적용되어 있고, 어떤 파티션에는 적용이 되지않은 중간(일관성이 깨진) 상태를 목격해서는 안된다.  성능(Performance): 테이블은 메타데이터를 제공하고 과도한 파일 나열을 피해야함, 그렇게 함으로써 쿼리 계획 과정 자체가 더 빨라지고 쿼리 계획이 필요한 파일만 스캔하므로 훨씬 빠르게 실행될 수 있음  사용 용이(Easy to Use): 파티셔닝 같은 기술의 이점을 얻으려면, 최종 사용자는 테이블의 물리적 구조를 알 필요가 없어야함, 테이블은 사용자에게 자연스럽고 직관적인 쿼리를 통해 파티셔닝의 이점을 제공할 수 있어야하고 이미 필터링하고 있는 컬럼(e.g. 타임스탬프 컬럼)에서 파생된 추가적인 파티션 컬럼(e.g. month 컬럼)을 또 필터링하는 방식에 의존하지 않아야 함.  진화/변경 가능함 (Evolvability): Hive 테이블의 스키마를 수정하면 안전하지 않은 트랜잭션 발생 가능, 테이블의 파티셔닝 방식을 변경할 때에는 전체 테이블 다시 작성 필요, 테이블은 스키마와 파티셔닝의 방식을 안전하게 변경할 수 있어야 하며 이를 위해 전체 재작성할 필요가 없어야 함.  확장성 (Scalability): 위 요구사항들이 페타바이트급 데이터에서 달성 가능해야 함. (Iceberg는 넷플릭스에서 만들었음!)            Apache Iceberg: The Definitive Guide, O’Reilly Media, 2024. p.16 &#8617;      ",
"tags": ["iceberg", "bigdata", "datalake"]
},

{
"title": "Welcome!",
"url": "/welcome/",
"content": "환영해요!",
"tags": []
}

]